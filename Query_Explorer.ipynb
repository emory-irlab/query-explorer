{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSbVyrpeiI2j"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install gradio=='3.21.0'\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "!pip install python-terrier\n",
        "!pip install coolname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-lt0LR1Hlnw_"
      },
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "from pyterrier.measures import * # don't uncomment this #ok\n",
        "import os\n",
        "import tqdm\n",
        "# import nltk\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import coolname\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_seeds():\n",
        "    print(f'torch seed = {torch.seed()}')\n",
        "    print(f'numpy seed = {np.random.seed()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHs0WgUbM-c0"
      },
      "outputs": [],
      "source": [
        "if not pt.started():\n",
        "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2OiVRcIYNdSs"
      },
      "outputs": [],
      "source": [
        "def cleanup(s1):\n",
        "    return \"\".join([x if x.isalnum() else \" \" for x in s1.strip()])\n",
        "\n",
        "def get_index(EVALUATION_NAME, index_name, field=None, colbert=False,):\n",
        "    if index_name == \"vaswani\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path)\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['text'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(pt_index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        print('Completed indexing')\n",
        "        if colbert:\n",
        "            return index, dataset, dataset.get_topics(), dataset.get_corpus_iter\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        return index, dataset, queries\n",
        "    if index_name == \"beir_dbpedia-entity\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path, meta={\"docno\": 200})\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['text', 'title', 'url'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(pt_index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        print('Completed indexing')\n",
        "        if colbert:\n",
        "            def corpus_iterator():\n",
        "                for y in dataset.get_corpus_iter():\n",
        "                    y['text'] = y['title'] + \" \" + y['text']\n",
        "                    if y['text'].strip():\n",
        "                        yield y\n",
        "            return index, dataset, dataset.get_topics(), corpus_iterator\n",
        "        return index, dataset, queries\n",
        "    if index_name == \"beir_webis-touche2020_v2\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path, meta={\"docno\": 39})\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['text', 'title', 'stance', 'url'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(pt_index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        print('Completed indexing')\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['description'].str.cat(queries['text'], sep=' ')\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        if colbert:\n",
        "            def corpus_iterator():\n",
        "                for y in dataset.get_corpus_iter():\n",
        "                    y['text'] = y['title'] + \" \" + y['text']\n",
        "                    if y['text'].strip():\n",
        "                        yield y\n",
        "            return index, dataset, queries, corpus_iterator\n",
        "        return index, dataset, queries\n",
        "    elif index_name == \"msmarco_passage\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path)\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['text'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(pt_index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        print('Completed indexing')\n",
        "        if colbert:\n",
        "            return index, dataset, dataset.get_topics(), dataset.get_corpus_iter\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        return index, dataset, queries\n",
        "    elif index_name == \"msmarco_document\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path)\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['url', 'title', 'body'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        print('Completed indexing')\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        return index, dataset, queries\n",
        "    elif index_name == \"trec-covid\":\n",
        "        print(f\"Loading Index {index_name}...\")\n",
        "        EVALUATION_NAME = \"irds:cord19/trec-covid\"\n",
        "        index_name = \"cord19/trec-covid\"\n",
        "        index_path = f'./indices/{index_name}'\n",
        "        pt_index_path = index_path + '/data.properties'\n",
        "        if not os.path.exists(pt_index_path):\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            indexer = pt.IterDictIndexer(index_path)\n",
        "            index_ref = indexer.index(dataset.get_corpus_iter(), fields=['title', 'doi', 'date', 'abstract'])\n",
        "        else:\n",
        "            dataset = pt.get_dataset(EVALUATION_NAME)\n",
        "            print('Using prebuilt index.')\n",
        "            index_ref = pt.IndexRef.of(index_path)\n",
        "        index = pt.IndexFactory.of(index_ref)\n",
        "        print('Completed indexing')\n",
        "        queries = dataset.get_topics()\n",
        "        queries['query'] = queries['title'].str.cat(queries['description'], sep=' ')\n",
        "        queries['query'] = queries['query'].apply(lambda text: text.replace(\"?\", \"\"))\n",
        "        queries['query'] = queries['query'].apply(cleanup)\n",
        "        if colbert:\n",
        "            def corpus_iterator():\n",
        "                for y in dataset.get_corpus_iter():\n",
        "                    y['text'] = y['title'] + \" \" + y['abstract']\n",
        "                    if y['text'].strip():\n",
        "                        yield y\n",
        "            return index, dataset, queries, corpus_iterator\n",
        "        return index, dataset, queries\n",
        "    else:\n",
        "        print(f\"KD:No index selected of name {index_name}.\")\n",
        "        return None\n",
        "\n",
        "def get_bm25_pipe(index_name, index):\n",
        "    if index_name in [\"trec-covid\", \"msmarco_passage\", \"msmarco_document\"]:\n",
        "        bm25 = pt.BatchRetrieve.from_dataset(index_name, 'terrier_stemmed', wmodel='BM25')\n",
        "        #bm25_10000 = pt.BatchRetrieve.from_dataset(index_name, 'terrier_stemmed', wmodel='BM25', num_results=10000)\n",
        "    else:\n",
        "        bm25 = pt.BatchRetrieve(index, wmodel='BM25')\n",
        "        #bm25_10000 = pt.BatchRetrieve.from_dataset(index_name, 'terrier_stemmed', wmodel='BM25', num_results=10000)\n",
        "    return bm25\n",
        "\n",
        "triplets = [\n",
        "['irds:msmarco-passage/trec-dl-2019/judged',  'msmarco_passage', 'text', 'text'],\n",
        "[\"irds:beir/webis-touche2020/v2\", \"beir_webis-touche2020_v2\", \"text\", \"text\"],\n",
        "[\"irds:beir/dbpedia-entity/test\", \"beir_dbpedia-entity\", 'text', 'text'],\n",
        "[\"irds:vaswani\", \"vaswani\", 'text', 'text']]\n",
        "\n",
        "bm25= None; tfidf= None; docno2doctext = None\n",
        "def on_dataset_change(dataset_name):\n",
        "  triplet = [t for t in triplets if t[1]==dataset_name][0]\n",
        "  EVALUATION_NAME = triplet[0]; index_name = triplet[1]; field = triplet[2]; doc_field = triplet[3]\n",
        "  index, dataset, queries, corpus_iterator = get_index(EVALUATION_NAME, index_name, field, colbert=True)\n",
        "  docno2doctext = {doc['docno']: doc[field] for doc in corpus_iterator()}\n",
        "  bm25 = pt.BatchRetrieve(index, wmodel='BM25')\n",
        "  tfidf = pt.BatchRetrieve(index, wmodel='TF_IDF')\n",
        "  return bm25, tfidf, docno2doctext\n",
        "\n",
        "def user_selects_different_index(index_id): # for dropdpwn\n",
        "  triplet = triplets[index_id]\n",
        "  return on_dataset_change(triplet[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fw5csaI_6JxR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "SAVED_DATA_DIRECTORY = \"saved_data\"\n",
        "if not os.path.exists(SAVED_DATA_DIRECTORY):\n",
        "  os.mkdir(SAVED_DATA_DIRECTORY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MNJPCG3QBe5"
      },
      "outputs": [],
      "source": [
        "dataset_names = [triplet[1] for triplet in triplets]\n",
        "# default is id=3\n",
        "bm25, tfidf, docno2doctext  = user_selects_different_index(3) # vaswani is the fastest to load. For testing use index_id = 3 (vaswani)\n",
        "retrieval_algos_dict = {'BM25': bm25, 'TF_IDF': tfidf}\n",
        "retrieval_algos_names = ['BM25','TF_IDF']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MssZ0jfSUTIo"
      },
      "outputs": [],
      "source": [
        "def get_doc_text(docno):\n",
        "  if docno not in docno2doctext.keys():\n",
        "    return f\"Document Text not found for Document ID = {docno}\"\n",
        "  return docno2doctext[docno]\n",
        "\n",
        "def retrieve_for_ui(query_text, pipeline):\n",
        "  searchresults1 = (pipeline%10).search(cleanup(query_text))\n",
        "  searchresults1['eng-text'] = searchresults1['docno'].apply(get_doc_text)\n",
        "  searchresults1['target-text'] = searchresults1['eng-text']\n",
        "  res = [row.to_dict() for index, row in searchresults1.iterrows()]\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4io17vV3bVx"
      },
      "outputs": [],
      "source": [
        "retrieve_for_ui('what is the capital of afghanistan', bm25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NMrUSYQ6WOMJ"
      },
      "outputs": [],
      "source": [
        "pdd1 = retrieve_for_ui('some search query', bm25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rTdejOKKjBLh"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "# for batch size = 1\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import (\n",
        "    BeamSearchScorer,\n",
        "    LogitsProcessorList,\n",
        "    StoppingCriteriaList,\n",
        "    MaxLengthCriteria,\n",
        "    ForcedBOSTokenLogitsProcessor,\n",
        "    HammingDiversityLogitsProcessor, MinLengthLogitsProcessor\n",
        ")\n",
        "\n",
        "def clean1( text):\n",
        "    text = text.replace('<pad>', '')\n",
        "    text = text.replace('</s>', '')\n",
        "    text = text.strip().capitalize()\n",
        "    if text.endswith('?'):\n",
        "        return text\n",
        "    else:\n",
        "        return text + \"?\"\n",
        "\n",
        "class DiverseGenerator(object):\n",
        "    def __init__(self, forced_bos=True, hamming=True, model_name='castorini/doc2query-t5-base-msmarco', start_words=['What','When','Which','Where','How']):\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "        self.model.to(device)\n",
        "        self.start_words = start_words\n",
        "        self.forced_bos = forced_bos\n",
        "        self.hamming = hamming\n",
        "    def clean(self, text):\n",
        "        return clean1(text)\n",
        "    def diverse_generate(self, document, num_beams = 20, basic_beam_search=True, hamming=False):\n",
        "        document_tokenized = self.tokenizer(document, return_tensors='pt')\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f'dev:{device}')\n",
        "        encoder_input_ids = document_tokenized['input_ids'].to(device)\n",
        "        generations = []\n",
        "        if basic_beam_search:\n",
        "            generated_ids = self.model.generate(encoder_input_ids, max_length=128,\n",
        "                                           pad_token_id=self.tokenizer.eos_token_id, num_beams=num_beams, num_return_sequences=5, temperature = 1.3,top_p=0.92, repetition_penalty =2.1, do_sample=True).tolist()\n",
        "            preds = [self.clean(self.tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True, )) for g in generated_ids]\n",
        "            generations.extend(preds)\n",
        "        input_ids = torch.ones((num_beams, 1), device=self.model.device, dtype=torch.long)\n",
        "        input_ids = input_ids * self.model.config.decoder_start_token_id\n",
        "        if hamming:\n",
        "            generations.extend(self.hamming_diverse(encoder_input_ids, input_ids,))\n",
        "        return generations\n",
        "    def hamming_diverse(self, encoder_input_ids, input_ids, num_beams = 6, num_beam_groups=3):\n",
        "        model_kwargs = {\n",
        "            \"encoder_outputs\": self.model.get_encoder()(\n",
        "                encoder_input_ids.repeat_interleave(num_beams, dim=0), return_dict=True\n",
        "            )\n",
        "        }\n",
        "        # instantiate beam scorer\n",
        "        beam_scorer = BeamSearchScorer(\n",
        "            batch_size=1,\n",
        "            max_length=self.model.config.max_length,\n",
        "            num_beams=num_beams,\n",
        "            num_beam_hyps_to_keep=num_beams,\n",
        "            device=self.model.device,\n",
        "            num_beam_groups=num_beam_groups,\n",
        "        )\n",
        "        logits_processor = LogitsProcessorList(\n",
        "            [HammingDiversityLogitsProcessor(5.5, num_beams=num_beams, num_beam_groups=num_beam_groups),\n",
        "             MinLengthLogitsProcessor(8, eos_token_id=self.model.config.eos_token_id),\n",
        "             ]\n",
        "        )\n",
        "        outputs = self.model.group_beam_search(\n",
        "            input_ids, beam_scorer, logits_processor=logits_processor, **model_kwargs\n",
        "        )\n",
        "        generations = []\n",
        "        for gen in self.tokenizer.batch_decode(outputs, skip_special_tokens=True):\n",
        "            generations.append(self.clean(gen))\n",
        "        #print(len(generations))\n",
        "        return generations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qHeFrNI3iLTp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def highlighted_doc(d):\n",
        "    #print(f\"D={str(d)}\")\n",
        "    document = d['eng-text']\n",
        "    event_str = d['event_str']\n",
        "    event_word_to_event = {e[0]['string']: str(e[0]['label']) for e in event_str}\n",
        "    if len(event_word_to_event)==0:\n",
        "        return []\n",
        "    highlights = []\n",
        "    for word in document.split(\" \"):\n",
        "        if word in event_word_to_event.keys():\n",
        "            event_type = event_word_to_event[word]\n",
        "            highlights.extend([(word, event_type)])\n",
        "        else:\n",
        "            highlights.extend([(word, None)])\n",
        "    return highlights\n",
        "\n",
        "def lang_to_emoji(lang):\n",
        "    if lang == \"fas\":\n",
        "        return \"🇮🇷 \"\n",
        "    if lang == \"eng\":\n",
        "        return \"🇺🇸 \"\n",
        "    if lang == 'kor':\n",
        "        return \"🇰🇷 \"\n",
        "    if lang == 'rus':\n",
        "        return \"🇷🇺 \"\n",
        "    if lang == 'zho':\n",
        "        return \"🇨🇳 \"\n",
        "    if lang =='ara':\n",
        "        return '🇸🇦 '\n",
        "    return \"📜\"\n",
        "\n",
        "NDOCS = 10\n",
        "max_text_lim = 400\n",
        "## need to update this with retrival method choosing\n",
        "\n",
        "def document_retriever(session, query_text,logs_file_name, model_choice_retrival=retrieval_algos_names[0], max_text_lim=400):\n",
        "    if logs_file_name != \"manual_search\":\n",
        "      on_query_change(query_text,logs_file_name, session)\n",
        "    retrieval_algo = retrieval_algos_dict[model_choice_retrival]\n",
        "    docs_all_lang = retrieve_for_ui(query_text, retrieval_algo)\n",
        "    #print(f\"docs_all_lang={docs_all_lang}\")\n",
        "    #print(f\"len(docs_all_lang) = {len(docs_all_lang)}\")\n",
        "    #print(f\"event_ann = {event_ann}\")\n",
        "    docs_to_ui = []\n",
        "    docs_en = [d['eng-text']  for d in docs_all_lang]\n",
        "    #print(f\"docs_en[0] = \" + docs_en[0])\n",
        "    #print(f\"len(docs_en) = {len(docs_en)}\")\n",
        "    docs_fas = [d['target-text'] for d in docs_all_lang]\n",
        "    docs_score = [d['score'] for d in docs_all_lang]\n",
        "    #print(f\"docs_fas[0] = \" + docs_fas[0])\n",
        "    #docs_fas = [str(d['events']).strip()[:500].strip() + \"...\" for d in event_ann]\n",
        "    docs_events = [\"\" for d in docs_en] # highlighted_doc(d)\n",
        "    for i in range(len(docs_en)):\n",
        "        #print(f\"i={str(i)}\")\n",
        "        #docs_to_ui.append(\"Title: \" + docs_title_dummy[i]) #lang_to_emoji(docs_fas[i]['lang'])+\n",
        "        dtran = str(docs_fas[i]).strip()[:max_text_lim].strip() + \"...\"\n",
        "        docs_to_ui.append(dtran)\n",
        "        deng = \"🇺🇸  \"+str(docs_en[i]).strip()[:max_text_lim].strip() + \"...\"\n",
        "        docs_to_ui.append(deng)\n",
        "        docs_to_ui.append(docs_score[i])\n",
        "        docs_to_ui.append(docs_events[i])\n",
        "    for i in range(len(docs_en), NDOCS):\n",
        "        docs_to_ui.append(\"\")\n",
        "        docs_to_ui.append(\"\")\n",
        "        docs_to_ui.append(\"\")\n",
        "        docs_to_ui.append(\"\")\n",
        "    if docs_to_ui is not None:\n",
        "        if len(docs_to_ui) == NDOCS*4:\n",
        "            return docs_to_ui\n",
        "    return [\"\"]*NDOCS*4\n",
        "\n",
        "def add_to_new_query(current_text_box, to_add):\n",
        "    return current_text_box + \" \" + to_add\n",
        "\n",
        "eg1=\"Eleven people were killed in a train crash in northern Italy...\"\n",
        "eg2=\"Based on the U.S. Electronics Network (CNN) cited Peruvian...\"\n",
        "def sample_doc_examples(inshort):\n",
        "    if inshort == eg1:\n",
        "        return \"Eleven people were killed in a train crash in northern Italy when the train crashed in the north of Italy The number of victims of the train disaster in northern Italy has grown to 11 people reported by the head of the administration of the autonomous province of Bolzano Louis Durnwalder.\"\n",
        "    if inshort == eg2:\n",
        "        return \"Based on the U.S. Electronics Network (CNN) cited Peruvian officials as saying that it is currently known that 2 people have died and 65 have been injured and the death toll has risen to 1 person.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBuIw1BLyFZu"
      },
      "outputs": [],
      "source": [
        "model_name0 = 'google/flan-t5-large'\n",
        "diverseGenerator = DiverseGenerator(model_name=model_name0)\n",
        "\n",
        "def update_model(model_name):\n",
        "  if model_name is not model_name0:\n",
        "    print(f\"Updating query generators to {model_name}\")\n",
        "    diverseGenerator = DiverseGenerator(model_name=model_name0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Pbh6WjugmIbj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# basic beam search\n",
        "#this is what we are using now to generate queries, kd pls change it if you want in gradio\n",
        "def query_generator1(prompt_instruction,prompt_context, prompt_input, model_name, session):\n",
        "    input = prompt_instruction + \"\\n\" + prompt_context+\"\\nDocument:\"+prompt_input+\"\\nQuery:\"\n",
        "    queries = diverseGenerator.diverse_generate(input)\n",
        "    queries = list(set(queries))\n",
        "    #random.shuffle(queries)\n",
        "    #queries.sort(key=len, reverse=True)\n",
        "    if len(queries) >= 5:\n",
        "        return session,*queries[0:5]\n",
        "    else:\n",
        "        ll = [\"\"] * 5\n",
        "        for (i,q) in enumerate(queries):\n",
        "            ll[i] = q\n",
        "        return session,*ll\n",
        "\n",
        "def query_generatortemp(prompt_instruction,prompt_context, prompt_input, model_name, session):\n",
        "    input = prompt_instruction + \"\\n\" + prompt_context+\"\\nDocument:\"+prompt_input+\"\\nQuery:\"\n",
        "    queries = diverseGenerator.diverse_generate(input)\n",
        "    queries = list(set(queries))\n",
        "    #random.shuffle(queries)\n",
        "    #queries.sort(key=len, reverse=True)\n",
        "    if len(queries) >= 5:\n",
        "        return session,*queries[0:5]\n",
        "    else:\n",
        "        ll = [\"\"] * 5\n",
        "        for (i,q) in enumerate(queries):\n",
        "            ll[i] = q\n",
        "        return session,*ll\n",
        "# hamming diversity beam search\n",
        "def query_generator2(input,model_name):\n",
        "    diverseGenerator = DiverseGenerator(model_name=model_name)\n",
        "    queries = diverseGenerator.diverse_generate(input, basic_beam_search=False, hamming=True)\n",
        "    queries = list(set(queries))\n",
        "    #random.shuffle(queries)\n",
        "    #queries.sort(key=len, reverse=True)\n",
        "    if len(queries) >= 5:\n",
        "        return queries[0:5]\n",
        "    else:\n",
        "        ll = [\"\"] * 5\n",
        "        for (i,q) in enumerate(queries):\n",
        "            ll[i] = q\n",
        "        return ll\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A9o7x4HBfcLx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "#saving docs\n",
        "def save_document_auto(session, model_name,file_name,query, *document_texts):\n",
        "    relevance_annotations = []\n",
        "    for i in range(0, len(document_texts), 4):\n",
        "        text1 = document_texts[i]\n",
        "        if(text1):\n",
        "            text2 = document_texts[i + 1]\n",
        "            score = document_texts[i + 2]\n",
        "            rating = document_texts[i + 3]\n",
        "            if not (rating):\n",
        "                rating = 0\n",
        "            id = i // 4 + 1\n",
        "            relevance_annotations.append({\"id\": id, \"doc_test\": text1, \"translation\": text2, \"score\":score,\"rating\": rating})\n",
        "    final_data = {\n",
        "        \"session\": session,\n",
        "        \"query\": query,\n",
        "        \"model_choice\":model_name,\n",
        "        \"relevance_annotations\": relevance_annotations,\n",
        "    }\n",
        "    folder_path = 'saved_data'\n",
        "    file_path = f'{folder_path}/{file_name}.json'\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "        with open(file_path, \"r\") as jsonfile:\n",
        "            data = json.load(jsonfile)\n",
        "            if isinstance(data, list):\n",
        "                data.append(final_data)\n",
        "            else:\n",
        "                data = [data, final_data]\n",
        "        with open(file_path, \"w\") as jsonfile:\n",
        "            json.dump(data, jsonfile, indent=4)\n",
        "    else:\n",
        "        with open(file_path, \"w\") as jsonfile:\n",
        "            json.dump([final_data], jsonfile, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "P7tnyXs8na-H"
      },
      "outputs": [],
      "source": [
        "instructions = [\"Generate a query which is relevant to a given document\",\n",
        "                \"Generate a query which is relevant to a given document and is different from previously generated query\",\n",
        "                \"Generate a document relevant query with different words from the document\"]\n",
        "instruction = instructions[0]\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "def get_flant5xl():\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\")\n",
        "    return tokenizer, model\n",
        "\n",
        "def dqpairs(documents, queries):\n",
        "  dqs = \"\\n\".join([f\"Document:{d}\\nQuery:{q}\" for (d,q) in zip(documents, queries)])\n",
        "  #dqs = f\"{instruction}:\\n\" + dqs\n",
        "  return dqs\n",
        "\n",
        "def dqprompt(documents, queries):\n",
        "  all_except_last = documents[:-1]\n",
        "  dqs = \"\\n\".join([f\"Document:{d}\\nQuery:{q}\" for (d,q) in zip(all_except_last, queries)])\n",
        "  #dqs = f\"{instruction}:\\n\" + dqs\n",
        "  dqs = dqs + f\"\\nDocument:{documents[-1]}\"\n",
        "  return dqs\n",
        "\n",
        "def get_dqlists_from_prompt(prompt_text):\n",
        "  dqs = prompt_text.split('\\n')\n",
        "  instruction = dqs[0]\n",
        "  ds = []\n",
        "  qs = []\n",
        "  for i in range(1, len(dqs) - 2, 2):\n",
        "    ds.append(dqs[i].split(\":\")[1])\n",
        "    qs.append(dqs[i+1].split(\":\")[1])\n",
        "  last_doc_not_needed = dqs[i].split(\":\")[1]\n",
        "  return ds, qs, instruction\n",
        "\n",
        "def update_prompt(model_input, document):\n",
        "    document = document.replace(\"🇺🇸\",\"\").strip()\n",
        "    ds, qs, instruction = get_dqlists_from_prompt(model_input)\n",
        "    # now keep last 2 doc-query pairs\n",
        "    if len(ds) > 2:\n",
        "        ds = ds[len(ds)-2:]\n",
        "        qs = qs[len(ds)-2:]\n",
        "    ds.append(document)\n",
        "    return instruction +\"\\n\"+ dqprompt(ds, qs) + \"\\nQuery:\"\n",
        "\n",
        "def send_feedback(input_query, document, model_choice_query, session, file_name=\"feedback_query_reformulations\"):\n",
        "  document = document.replace(\"🇺🇸\",\"\").strip()\n",
        "  rf_queries = query_generator1(f\"Based on the given context ```{document}```, generate keywords for the query : \",\"\", input_query,model_choice_query, session)\n",
        "  ref_query = input_query + \" \" + rf_queries[1]\n",
        "  on_query_change(ref_query, file_name, session)\n",
        "  return ref_query\n",
        "\n",
        "def append_keywords(session, query, reform_method, reform_instruction, model_choice_query, file_name=\"query_reformulations\"):\n",
        "  rf_queries = query_generator1(f\"Generate keywords for the query : \",\"\", query, model_choice_query, session)\n",
        "  ref_query = query + \" \" + rf_queries[1]\n",
        "  on_query_change(ref_query, file_name, session)\n",
        "  return ref_query\n",
        "\n",
        "ds_eg = [\"24 Aug 2016 At least 38 people died in a powerful earthquake that hit central Italy early on Wednesday 250 people are now known to have died in the earthquake that hit central Italy on Wednesday\",\n",
        "      \"As of Thursday morning, the deaths totaled 241, officials said. 6.2 Earthquake In Central Italy, At Least 37 Dead\"]\n",
        "qs_eg = [\"When did the earthquake happen?\", \"How many people died in the earthquake?\"]\n",
        "\n",
        "sample_docs = [\"China’s state-run Citic Group, the main developer of the project, said negotiations were ongoing and that the $1.3bn was to be spent on the “initial phase” of the port, adding the project was divided into four phases. It did not elaborate on plans for subsequent stages. Xi and Mitsotakis will visit the port of Piraeus, Greece’s largest and majority owned by Chinese port operator Cosco. It is the biggest Chinese investment in Greece and Cosco recently received approval for a new investment plan that includes building a new cargo terminal.\",\n",
        "               \"FireEye, one of the largest cyber security companies in the United States, said on Tuesday that it had been hacked, likely by a government, and that an arsenal of hacking tools used to test the defences of its clients had been stolen.  The hack of FireEye, a company with an array of contracts across the national security space both in the United States and its allies, is among the most significant breaches in recent memory.\",\n",
        "               \"The alleged state-backed hacking groups engaging in these attacks include a group from Russia code-named ‘Strontium’ and two groups from North Korea code-named ‘Zinc’ and ‘Cerium’. \"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f5FvzofgoNiy"
      },
      "outputs": [],
      "source": [
        "def display_inter_search_content(file_name):\n",
        "    try:\n",
        "        with open(f'saved_data/{file_name}', 'r') as file:\n",
        "            data = json.load(file)\n",
        "            content = \"\"\n",
        "            for entry in data:\n",
        "                if len(entry['relevance_annotations']) >1:\n",
        "                    query = \"Query: \" + entry[\"query\"]\n",
        "                    content += f\"<h3>{query}</h3>\"\n",
        "                    if entry[\"model_choice\"]:\n",
        "                        model_choice = \"Model Choice: \" + str(entry[\"model_choice\"])\n",
        "                        content += f\"<h4>{model_choice}</h4>\"\n",
        "                    if entry[\"session\"]:\n",
        "                        session_choice = \"Session_iD: \" + str(entry[\"session\"])\n",
        "                        content += f\"<h4>{session_choice}</h4>\"\n",
        "                    df = pd.DataFrame(entry[\"relevance_annotations\"])\n",
        "                    df.rename(columns={'doc_test': 'Doc_Test', 'translation': 'Translation', 'score': 'Score', 'rating': 'Rating'}, inplace=True)\n",
        "                    content += df.to_html(border=0, index=False)\n",
        "            return content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def read_jsonl(file_path):\n",
        "    return pd.read_json(file_path, lines=True)\n",
        "\n",
        "def display_jsonl_content(file_name, session_id):\n",
        "    if file_name == 'interactive_search.json':\n",
        "        return display_inter_search_content(file_name)\n",
        "    try:\n",
        "        df = read_jsonl(f'saved_data/{file_name}')\n",
        "        if session_id and session_id != \"Everyone\":\n",
        "            df = df[df['Session'] == session_id]\n",
        "        content = \"\"\n",
        "        column_names = df.columns\n",
        "        for index, row in df.iterrows():\n",
        "            for col in column_names:\n",
        "                content += f\"<p><b>{col.capitalize()}:</b> {row[col]}</p>\"\n",
        "            content += \"<hr>\"\n",
        "        return content if content else \"No data found for this session ID\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def list_files(directory):\n",
        "    return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
        "\n",
        "\n",
        "def get_unique_sessions(file_name):\n",
        "    try:\n",
        "        df = read_jsonl(f'{SAVED_DATA_DIRECTORY}/{file_name}')\n",
        "        return df['Session'].unique().tolist()\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "\n",
        "directory = f'{SAVED_DATA_DIRECTORY}/'\n",
        "\n",
        "\n",
        "def generate_cool_name():\n",
        "    name1 = coolname.generate_slug(2)+f'{random.randint(10, 99)}'\n",
        "    return name1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HeXZzGJy8s_f"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(file_name, data):\n",
        "    data = json.dumps(data)\n",
        "    try:\n",
        "        with open(file_name, 'a+') as file:\n",
        "            file.write(data + \"\\n\")\n",
        "    except FileNotFoundError:\n",
        "        with open(file_name, 'w') as file:\n",
        "            json.dump(data, file)\n",
        "\n",
        "previous_values = {}\n",
        "\n",
        "\n",
        "def on_query_change(query, file_name, session):\n",
        "    file_name_log = directory + \"query_log.json\"\n",
        "    previous_query = previous_values.get(session, '')\n",
        "    previous_content_to_log = \"null\" if previous_query == '' else previous_query\n",
        "    data = {\n",
        "        'session': session,\n",
        "        'type': 'query',\n",
        "        'query_reformulator_type':file_name,\n",
        "        'previous_content': previous_content_to_log,\n",
        "        'current_content': query,\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "    write_to_jsonl(file_name_log, data)\n",
        "    previous_values[session] = query\n",
        "\n",
        "\n",
        "def save_relavance_annotations(session, query, document, rating):\n",
        "  if rating == \"\":\n",
        "    return\n",
        "  file_name_log = directory + \"relavance_annotations.json\"\n",
        "  data = {\n",
        "        'session': session,\n",
        "        'type': 'annotation',\n",
        "        'query': query,\n",
        "        'document': document,\n",
        "        'annotation': rating,\n",
        "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "  write_to_jsonl(file_name_log, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LEPLUKv_tksu"
      },
      "outputs": [],
      "source": [
        "query_model_choices = ['castorini/doc2query-t5-base-msmarco','google/flan-t5-large']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fzNG9-VDcrwI"
      },
      "outputs": [],
      "source": [
        "def display_session_name(session_id):\n",
        "    return session_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duFxEbITi2jM"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(\"Query Tuner\") as demo:\n",
        "    session = gr.Textbox(info=\"Your\", visible=False)\n",
        "    demo.load(fn=generate_cool_name, inputs=None, outputs=session)\n",
        "    with gr.Tab(\"🤖 User Interface\"):\n",
        "        with gr.Row():\n",
        "          # QBE\n",
        "          prompt_input = gr.Textbox(label=\"Provide Example Document\",info=\"This document would be used to generate a query\",\n",
        "                                        value=sample_docs[0])\n",
        "          # Ad-hoc\n",
        "          interactive_query = gr.Textbox(value=(\" \"*len(sample_docs[0])), label=\"Search Query\", info=\"Search and Retrieve documents for one of the generated queries\", interactive=True)\n",
        "        with gr.Row():\n",
        "          with gr.Column():\n",
        "            btni3 = gr.Button(value =\"⚙️ Generate Query                    \",  size=\"sm\")\n",
        "            outputs3 = []\n",
        "            rds3 = []\n",
        "            for i in range(5):\n",
        "              with gr.Row():\n",
        "                with gr.Column():\n",
        "                  outputs3.append(gr.Textbox(value=\"\", label=f\"Query {str(i+1)}\", interactive=True))\n",
        "                  rds3.append(gr.Checkbox(label=\"Add to query\",elem_id=f\"cb{str(i)}\",interactive=True))\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "              btn_reform = gr.Button(value=\"Reformulate\", size=\"sm\", css=\".gradio-container { width: 2.5vw}\")\n",
        "              btn2 = gr.Button(value=\"🔍 Search\", size=\"sm\", css=\".gradio-container { width: 5vw}\")\n",
        "            docs_en2 = []\n",
        "            rds4 = []\n",
        "            for i in range(NDOCS):\n",
        "              with gr.Row():\n",
        "                with gr.Column():\n",
        "                  dx = gr.Textbox(value=\"\",  label=f\"Document {str(i+1)}\", lines=3)\n",
        "                  docs_en2.append(dx)\n",
        "                  docs_en2.append(gr.Textbox(value=\"\", label=\"Translation\", lines=3))\n",
        "                  docs_en2.append(gr.Textbox(value=\"\", label=\"Score\", lines=3, visible=False))\n",
        "                  with gr.Row():\n",
        "                    slider = gr.Slider(minimum=0, maximum=10, label=f\"Rate Document {i+1}\", value=-1)\n",
        "                    slider.change(save_relavance_annotations, inputs=[session, interactive_query, dx, slider])\n",
        "                    docs_en2.append(slider)\n",
        "                    # docs_en2.append(gr.HighlightedText(value=\"\", label=f\"Event Annotations of Document {str(i+1)}\"))\n",
        "                    rds4.append(gr.Checkbox(label=\"Use this document to improve the query\", elem_id=f\"cb{str(i)}\", interactive=True))\n",
        "            for i in range(5):\n",
        "              rds3[i].select(fn=add_to_new_query, inputs=[interactive_query, outputs3[i]], outputs=interactive_query)\n",
        "            save_btn_inter = gr.Button(value=\"💾 Save Results\" , size=\"sm\", css=\".gradio-container { width: 5vw}\")\n",
        "        filename_input = gr.Textbox(value='interactive_search', visible=False)\n",
        "        btn2.click(lambda x:[False]*NDOCS, inputs=None, outputs=rds4)\n",
        "        btni3.click(lambda x:\"\", inputs=None, outputs=interactive_query)\n",
        "        btni3.click(lambda x:[False]*5, inputs=None, outputs=rds3)\n",
        "    with gr.Tab(\"⚙️ Configuration\"):\n",
        "        json_choice_list = ['interactive_search.json','query_log.json', 'relavance_annotations.json']\n",
        "        with gr.Row():\n",
        "            model_choice_query = gr.Dropdown(\n",
        "                label=\"Select Query Generator\",\n",
        "                choices = query_model_choices,\n",
        "                value=query_model_choices[1] ,\n",
        "                size=\"sm\"\n",
        "              )\n",
        "            prompt_instruction = gr.Dropdown(instructions,label=\"Choose Instruction\",info=\"Different instructions can invoke a variety of responses from LLMs\",value=instructions[1],interactive=True )\n",
        "            prompt_context = gr.Textbox(label=\"Sample Document-Query Pairs\",\n",
        "                                    placeholder=\"Provide text to generate query...\", value=dqpairs(ds_eg[1:], qs_eg[1:]),\n",
        "                                       lines=5)\n",
        "            btni3.click(query_generatortemp, inputs=[prompt_instruction,prompt_context, prompt_input,model_choice_query, session], outputs=[session,*outputs3])\n",
        "        with gr.Row():\n",
        "          reform_method = gr.Dropdown(['Zero-Shot QR', 'Few-Shot QR'],\n",
        "                                   label=\"Choose Type of Query Reformulator\",info=\"Additional keywords would be added to your original query\",\n",
        "                                   value='Zero-Shot QR')\n",
        "          reform_instruction = gr.Textbox(value=\"Suggest useful keywords to improve the retrieval effectiveness of the query: \", label=\"Reformulator Instruction\", info=\"Use the following instruction to reform the query inplace\", interactive=True)\n",
        "          reform_context = gr.Textbox(label=\"Sample Query-Reformed Query Pairs\",\n",
        "                                    placeholder=\"Provide text to generate query...\", value=\"\",\n",
        "                                       lines=5)\n",
        "        with gr.Row():\n",
        "            model_choice_retrival = gr.Dropdown(\n",
        "                label=\"Select retrieval pipeline to use\", info=\"The query would be run against the index to retrieve the top 10 documents.\",\n",
        "                choices=retrieval_algos_names,\n",
        "                value=retrieval_algos_names[0],\n",
        "              )\n",
        "            index_choice_retrieval = gr.Dropdown(\n",
        "                label=\"Select retrieval index to use\", info=\"The query would be run against this index.\",\n",
        "                choices=dataset_names,\n",
        "                value=dataset_names[3],\n",
        "              )\n",
        "            index_choice_retrieval.change(on_dataset_change, inputs=index_choice_retrieval)\n",
        "            btn2.click(document_retriever, inputs=[session, interactive_query, filename_input, model_choice_retrival], outputs=docs_en2)\n",
        "            btn2.click(save_document_auto, inputs = [session, model_choice_retrival,filename_input,interactive_query,*docs_en2])\n",
        "        with gr.Row():\n",
        "            dropdown = gr.Dropdown(choices=json_choice_list, label=\"Select JSON File\")\n",
        "            display_button = gr.Button(\"Display Recorded Annotations & Logs\")\n",
        "        output = gr.HTML()\n",
        "        model_choice_query.change(update_model, inputs=model_choice_query)\n",
        "        display_button.click(display_jsonl_content, inputs=dropdown, outputs=output)\n",
        "        save_btn_inter.click(save_document_auto, inputs = [session, model_choice_retrival,filename_input,interactive_query,*docs_en2])\n",
        "        btn_reform.click(append_keywords, inputs=[session, interactive_query, reform_method, reform_instruction, model_choice_query], outputs=interactive_query)\n",
        "        for i in range(NDOCS):\n",
        "              rds4[i].select(fn=send_feedback, inputs=[interactive_query, docs_en2[3*i + 1], model_choice_query, session], outputs=interactive_query)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG7e97FNnnyr"
      },
      "outputs": [],
      "source": [
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_Mkpefo8MgA"
      },
      "outputs": [],
      "source": [
        "demo.close()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}